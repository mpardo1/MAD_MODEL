if(sols < 25){
index <- order(logl, decreasing = T)[1:25]
} else {
index <- order(logl, decreasing = T)[1:sols]
}
n <- 1
parmat <- matrix(NA, nrow = length(index), ncol = 3)
for(i in index){
parmat[n, ] <- lhs[[i]]$par
n <- n + 1
}
# Muestreamos las mejores combinaciones de parámetros, cada uno de ellos
# independientemente. De esta forma estamos rompiendo las posibles
# correlaciones entre los parámetros, y en algún sentido, hacemos la
# aproximación menos bayesiana al no samplear la distribución multidimensional
# de los parámetros.
seeds <- t(apply(X = parmat, MARGIN = 2, sample, size = 100000, replace = T))
rm(parmat)
rm(lhs)
print(paste0("Round: ", round, ";  Best likelihood: ", best2,
"; Solutions: ", sols, "\n"))
best <- best2
round <- round + 1
}
rm(list = ls())
library("parallel")
library("tidyverse")
library("deSolve")
# Create pseudo data:
# Create Pseudo Data:
Path = "~/MAD_MODEL/SUR_MODEL/Code/"
setwd(Path)
system("R CMD SHLIB model_5eq.c")
dyn.load("model_5eq.so")
gam1 = 0.2
gam2 = 1.2
gam3 = 3
# We create a vector with the constant parameters.
parms = c(gam1,gam2,gam3)
# We set the initial conditions to zero.
Y <- c(y1 = 0, y2=0, y3=0, y4 = 0, y5 = 0)
Path = "~/MAD_MODEL/SUR_MODEL/data/Downloads_2378.data"
down <- data.frame(t(read.table(Path, header=FALSE)))
colnames(down) <- c("time", "down")
# List with the data frames of the forcings, sort as the c code.
forcs_mat <- list(data.matrix(down))
min_t <- min(down$time)
max_t <- max(down$time)
times <- seq(min_t,max_t, 1)
out <- ode(Y, times, func = "derivs",
parms = parms, dllname = "model_5eq",
initfunc = "initmod", nout = 1,
outnames = "Sum", initforc = "forcc",
forcings = down,
fcontrol = list(method = "constant"))
ode <- data.frame(out)
ode$Sum <- NULL
saveRDS(ode, file = "~/MAD_MODEL/SUR_MODEL/Code/ode_pseudo_5eq.rds")
# Esta función está adaptada para su uso con el paquete deSolve, el estándar en
# R para las ODE
Path = "~/MAD_MODEL/SUR_MODEL/Code/"
setwd(Path)
system("R CMD SHLIB model_5eq.c")
dyn.load("model_5eq.so")
ll_ode <- function(x, # vector con los parámetros
forcings, # forzamientos para el solver de la ode
y, # datos
devs){ #desviaciones estándar para calcular la loglikelihood
if(x[1] < 0 | x[2] < 0 | x[3] < 0){
res = -86829146000
}else{
pars <- c(gam1 = x[1], # death rate group 1
gam2 = x[2], # death rate group 2
gam3 = x[3]) # death rate group 3
population <- c(y1 = 0.0, y2 = 0.0, y3 = 0.0, y4 = 0.0, y5 = 0.0) #Vector inicial para ODE
forcs_mat <- list(data.matrix(forcings))
z <- ode(y = population,
times = 0:nrow(y), func = "derivs", method = "ode45",
dllname = "model_5eq", initfunc = "initmod", nout = 0,
parms = pars, initforc = "forcc", forcings = forcs_mat,
fcontrol = list(method = "constant")) #Aquí corre el ODE
colnames(z)[2:7] <- c("P1", "P2", "P3", "P4", "P5")
z <- as.data.frame(z)
z <- z[-1, ]
P1 <- y$X1
P2 <- y$X2
P3 <- y$X3
P4 <- y$X4
P5 <- y$X5
res <- #cálculo de la loglikelihood en función de las desviaciones estándar
sum(dnorm(z$P1 - P1, sd = devs[1], log = T)) +
sum(dnorm(z$P2 - P2, sd = devs[2], log = T)) +
sum(dnorm(z$P3 - P3, sd = devs[3], log = T)) +
sum(dnorm(z$P4 - P4, sd = devs[4], log = T)) +
sum(dnorm(z$P5 - P5, sd = devs[5], log = T))
}
return(res)
}
# Registrations:
Path = "~/MAD_MODEL/SUR_MODEL/data/Observed_data_2300.data"
ob_data <- readRDS(file = "~/MAD_MODEL/SUR_MODEL/Code/ode_pseudo_5eq.rds")
colnames(ob_data) <- c("time", "X1", "X2", "X3", "X4", "X5")
n_inicio <- 1
n_fin <- 2000
input2 <- ob_data[n_inicio:n_fin, ]
devs <- c()
spl <- (input2$X1)
fit <- smooth.spline(x = 1:nrow(input2), y = spl, df = 4)
devs[1] <- sd(spl - predict(fit)$y)
spl <- input2$X2
fit <- smooth.spline(x = 1:nrow(input2), y = spl, df = 4)
devs[2] <- sd(spl - predict(fit)$y)
spl <- input2$X3
fit <- smooth.spline(x = 1:nrow(input2), y = spl, df = 4)
devs[3] <- sd(spl - predict(fit)$y)
spl <- input2$X4
fit <- smooth.spline(x = 1:nrow(input2), y = spl, df = 4)
devs[4] <- sd(spl - predict(fit)$y)
spl <- input2$X5
fit <- smooth.spline(x = 1:nrow(input2), y = spl, df = 4)
devs[5] <- sd(spl - predict(fit)$y)
# Registrations:
Path = "~/MAD_MODEL/SUR_MODEL/data/Downloads_2378.data"
down <- data.frame(t(read.table(Path, header=FALSE)))
colnames(down) <- c("time", "down")
best <- -999999999 #LL inicial a mejorar
# load("seeds_CAN.RData") #Cargamos seeds de los valores iniciales de los pars.
seeds <- matrix( runif(30,0,1), ncol = 10, nrow = 3)
sols <- NA #Pre-aloco el número de combinaciones paramétricas en 2 unidades de LL de la mejor
set.seed(476468713)
condition <- T
round <- 1
# sims <- 2 #Número de combinaciones paramétricas a explorar
sims <- ncol(seeds) #Número de combinaciones paramétricas a explorar
Cores <- 19 #Numero de cores a utilizar.
it <- 0
while(condition){
#Ahora viene la paralelización
parall <- mclapply(1:sims, mc.cores = Cores, mc.preschedule = F,function(k){
it <- it + 1
fit <- optim(par = seeds[, k], fn = ll_ode, forcings = down, y = input2,
devs = devs, control = list(fnscale = -1, maxit = 500, parscale = seeds[, k]))
if((k %% 1000) == 0) {
cat("This was seed no. ", k, "\n")
cat("This fit: ", fit$value, "\n")
}
fit
})
lhs <- parall
rm(parall) #Para evitar fugas de memoria
filename <- paste0("param_MAD_MODEL", round, ".RData") #Salva cada ronda de optimizaciones, por si acaso
save(lhs, file = filename)
# Ahora, recuperamos la loglikelihood de cada combinación de parámetros
logl <- rep(NA, sims)
for(i in 1:sims) logl[i] <- lhs[[i]]$value
# Evaluamos las condiciones para parar el bucle
best2 <- max(logl, na.rm = T)
pc1 <- best < best2
pc2 <- best > (best2 - 2)
sols <- sum(logl > (max(logl, na.rm = T) - 2), na.rm = T)
pc3 <- sols > 1000
condition <- pc1 * pc2 * pc3
condition <- !condition
# Seleccionamos las mejores combinaciones de parámetros para mandar una nueva
# ronda, cogemos las combinaciones que estén a 2 unidades de distancia de la
# mejor, o en su defecto, las 250 mejores combinaciones.
if(sols < 25){
index <- order(logl, decreasing = T)[1:25]
} else {
index <- order(logl, decreasing = T)[1:sols]
}
n <- 1
parmat <- matrix(NA, nrow = length(index), ncol = 3)
for(i in index){
parmat[n, ] <- lhs[[i]]$par
n <- n + 1
}
# Muestreamos las mejores combinaciones de parámetros, cada uno de ellos
# independientemente. De esta forma estamos rompiendo las posibles
# correlaciones entre los parámetros, y en algún sentido, hacemos la
# aproximación menos bayesiana al no samplear la distribución multidimensional
# de los parámetros.
seeds <- t(apply(X = parmat, MARGIN = 2, sample, size = 100000, replace = T))
rm(parmat)
rm(lhs)
print(paste0("Round: ", round, ";  Best likelihood: ", best2,
"; Solutions: ", sols, "\n"))
best <- best2
round <- round + 1
}
print("The optimization finished.")
#Ahora viene la paralelización
parall <- mclapply(1:sims, mc.cores = Cores, mc.preschedule = F,function(k){
it <- it + 1
fit <- optim(par = seeds[, k], fn = ll_ode, forcings = down, y = input2,
devs = devs, control = list(fnscale = -1, maxit = 500, parscale = seeds[, k]))
if((k %% 1000) == 0) {
cat("This was seed no. ", k, "\n")
cat("This fit: ", fit$value, "\n")
}
fit
})
while(condition){
#Ahora viene la paralelización
parall <- mclapply(1:sims, mc.cores = Cores, mc.preschedule = F,function(k){
it <- it + 1
fit <- optim(par = seeds[, k], fn = ll_ode, forcings = down, y = input2,
devs = devs, control = list(fnscale = -1, maxit = 500, parscale = seeds[, k]))
if((k %% 1000) == 0) {
cat("This was seed no. ", k, "\n")
cat("This fit: ", fit$value, "\n")
}
fit
})
lhs <- parall
rm(parall) #Para evitar fugas de memoria
filename <- paste0("param_MAD_MODEL", round, ".RData") #Salva cada ronda de optimizaciones, por si acaso
save(lhs, file = filename)
# Ahora, recuperamos la loglikelihood de cada combinación de parámetros
logl <- rep(NA, sims)
for(i in 1:sims) logl[i] <- lhs[[i]]$value
# Evaluamos las condiciones para parar el bucle
best2 <- max(logl, na.rm = T)
pc1 <- best < best2
pc2 <- best > (best2 - 2)
sols <- sum(logl > (max(logl, na.rm = T) - 2), na.rm = T)
pc3 <- sols > 1000
condition <- pc1 * pc2 * pc3
condition <- !condition
# Seleccionamos las mejores combinaciones de parámetros para mandar una nueva
# ronda, cogemos las combinaciones que estén a 2 unidades de distancia de la
# mejor, o en su defecto, las 250 mejores combinaciones.
if(sols < 25){
index <- order(logl, decreasing = T)[1:25]
} else {
index <- order(logl, decreasing = T)[1:sols]
}
n <- 1
parmat <- matrix(NA, nrow = length(index), ncol = 3)
for(i in index){
parmat[n, ] <- lhs[[i]]$par
n <- n + 1
}
# Muestreamos las mejores combinaciones de parámetros, cada uno de ellos
# independientemente. De esta forma estamos rompiendo las posibles
# correlaciones entre los parámetros, y en algún sentido, hacemos la
# aproximación menos bayesiana al no samplear la distribución multidimensional
# de los parámetros.
seeds <- t(apply(X = parmat, MARGIN = 2, sample, size = 100000, replace = T))
rm(parmat)
rm(lhs)
print(paste0("Round: ", round, ";  Best likelihood: ", best2,
"; Solutions: ", sols, "\n"))
best <- best2
round <- round + 1
}
fit <- optim(par = seeds[, k], fn = ll_ode, forcings = down, y = input2,
devs = devs, control = list(fnscale = -1, maxit = 500, parscale = seeds[, k]))
k=2
fit <- optim(par = seeds[, k], fn = ll_ode, forcings = down, y = input2,
devs = devs, control = list(fnscale = -1, maxit = 500, parscale = seeds[, k]))
ll_ode <- function(x, # vector con los parámetros
forcings, # forzamientos para el solver de la ode
y, # datos
devs){ #desviaciones estándar para calcular la loglikelihood
if(x[1] < 0 | x[2] < 0 | x[3] < 0){
res = -86829146000
}else{
pars <- c(gam1 = x[1], # death rate group 1
gam2 = x[2], # death rate group 2
gam3 = x[3]) # death rate group 3
population <- c(y1 = 0.0, y2 = 0.0, y3 = 0.0, y4 = 0.0, y5 = 0.0) #Vector inicial para ODE
forcs_mat <- list(data.matrix(forcings))
z <- ode(y = population,
times = 0:nrow(y), func = "derivs", method = "ode45",
dllname = "model_5eq", initfunc = "initmod", nout = 0,
parms = pars, initforc = "forcc", forcings = forcs_mat,
fcontrol = list(method = "constant")) #Aquí corre el ODE
colnames(z)[2:6] <- c("P1", "P2", "P3", "P4", "P5")
z <- as.data.frame(z)
z <- z[-1, ]
P1 <- y$X1
P2 <- y$X2
P3 <- y$X3
P4 <- y$X4
P5 <- y$X5
res <- #cálculo de la loglikelihood en función de las desviaciones estándar
sum(dnorm(z$P1 - P1, sd = devs[1], log = T)) +
sum(dnorm(z$P2 - P2, sd = devs[2], log = T)) +
sum(dnorm(z$P3 - P3, sd = devs[3], log = T)) +
sum(dnorm(z$P4 - P4, sd = devs[4], log = T)) +
sum(dnorm(z$P5 - P5, sd = devs[5], log = T))
}
return(res)
}
# Registrations:
Path = "~/MAD_MODEL/SUR_MODEL/data/Observed_data_2300.data"
ob_data <- readRDS(file = "~/MAD_MODEL/SUR_MODEL/Code/ode_pseudo_5eq.rds")
colnames(ob_data) <- c("time", "X1", "X2", "X3", "X4", "X5")
n_inicio <- 1
n_fin <- 2000
input2 <- ob_data[n_inicio:n_fin, ]
devs <- c()
spl <- (input2$X1)
fit <- smooth.spline(x = 1:nrow(input2), y = spl, df = 4)
devs[1] <- sd(spl - predict(fit)$y)
spl <- input2$X2
fit <- smooth.spline(x = 1:nrow(input2), y = spl, df = 4)
devs[2] <- sd(spl - predict(fit)$y)
spl <- input2$X3
fit <- smooth.spline(x = 1:nrow(input2), y = spl, df = 4)
devs[3] <- sd(spl - predict(fit)$y)
spl <- input2$X4
fit <- smooth.spline(x = 1:nrow(input2), y = spl, df = 4)
devs[4] <- sd(spl - predict(fit)$y)
spl <- input2$X5
fit <- smooth.spline(x = 1:nrow(input2), y = spl, df = 4)
devs[5] <- sd(spl - predict(fit)$y)
# Registrations:
Path = "~/MAD_MODEL/SUR_MODEL/data/Downloads_2378.data"
down <- data.frame(t(read.table(Path, header=FALSE)))
colnames(down) <- c("time", "down")
best <- -999999999 #LL inicial a mejorar
# load("seeds_CAN.RData") #Cargamos seeds de los valores iniciales de los pars.
seeds <- matrix( runif(30,0,1), ncol = 10, nrow = 3)
sols <- NA #Pre-aloco el número de combinaciones paramétricas en 2 unidades de LL de la mejor
set.seed(476468713)
condition <- T
round <- 1
# sims <- 2 #Número de combinaciones paramétricas a explorar
sims <- ncol(seeds) #Número de combinaciones paramétricas a explorar
Cores <- 19 #Numero de cores a utilizar.
it <- 0
while(condition){
#Ahora viene la paralelización
parall <- mclapply(1:sims, mc.cores = Cores, mc.preschedule = F,function(k){
it <- it + 1
fit <- optim(par = seeds[, k], fn = ll_ode, forcings = down, y = input2,
devs = devs, control = list(fnscale = -1, maxit = 500, parscale = seeds[, k]))
if((k %% 1000) == 0) {
cat("This was seed no. ", k, "\n")
cat("This fit: ", fit$value, "\n")
}
fit
})
lhs <- parall
rm(parall) #Para evitar fugas de memoria
filename <- paste0("param_MAD_MODEL", round, ".RData") #Salva cada ronda de optimizaciones, por si acaso
save(lhs, file = filename)
# Ahora, recuperamos la loglikelihood de cada combinación de parámetros
logl <- rep(NA, sims)
for(i in 1:sims) logl[i] <- lhs[[i]]$value
# Evaluamos las condiciones para parar el bucle
best2 <- max(logl, na.rm = T)
pc1 <- best < best2
pc2 <- best > (best2 - 2)
sols <- sum(logl > (max(logl, na.rm = T) - 2), na.rm = T)
pc3 <- sols > 1000
condition <- pc1 * pc2 * pc3
condition <- !condition
# Seleccionamos las mejores combinaciones de parámetros para mandar una nueva
# ronda, cogemos las combinaciones que estén a 2 unidades de distancia de la
# mejor, o en su defecto, las 250 mejores combinaciones.
if(sols < 25){
index <- order(logl, decreasing = T)[1:25]
} else {
index <- order(logl, decreasing = T)[1:sols]
}
n <- 1
parmat <- matrix(NA, nrow = length(index), ncol = 3)
for(i in index){
parmat[n, ] <- lhs[[i]]$par
n <- n + 1
}
# Muestreamos las mejores combinaciones de parámetros, cada uno de ellos
# independientemente. De esta forma estamos rompiendo las posibles
# correlaciones entre los parámetros, y en algún sentido, hacemos la
# aproximación menos bayesiana al no samplear la distribución multidimensional
# de los parámetros.
seeds <- t(apply(X = parmat, MARGIN = 2, sample, size = 100000, replace = T))
rm(parmat)
rm(lhs)
print(paste0("Round: ", round, ";  Best likelihood: ", best2,
"; Solutions: ", sols, "\n"))
best <- best2
round <- round + 1
}
while(condition){
#Ahora viene la paralelización
parall <- mclapply(1:sims, mc.cores = Cores, mc.preschedule = F,function(k){
it <- it + 1
fit <- optim(par = seeds[, k], fn = ll_ode, forcings = down, y = input2,
devs = devs, control = list(fnscale = -1, maxit = 500, parscale = seeds[, k]))
if((k %% 1000) == 0) {
cat("This was seed no. ", k, "\n")
cat("This fit: ", fit$value, "\n")
}
fit
})
lhs <- parall
rm(parall) #Para evitar fugas de memoria
filename <- paste0("param_MAD_MODEL", round, ".RData") #Salva cada ronda de optimizaciones, por si acaso
save(lhs, file = filename)
# Ahora, recuperamos la loglikelihood de cada combinación de parámetros
logl <- rep(NA, sims)
for(i in 1:sims) logl[i] <- lhs[[i]]$value
# Evaluamos las condiciones para parar el bucle
best2 <- max(logl, na.rm = T)
pc1 <- best < best2
pc2 <- best > (best2 - 2)
sols <- sum(logl > (max(logl, na.rm = T) - 2), na.rm = T)
pc3 <- sols > 1000
condition <- pc1 * pc2 * pc3
condition <- !condition
# Seleccionamos las mejores combinaciones de parámetros para mandar una nueva
# ronda, cogemos las combinaciones que estén a 2 unidades de distancia de la
# mejor, o en su defecto, las 250 mejores combinaciones.
if(sols < 2){
index <- order(logl, decreasing = T)[1:2]
} else {
index <- order(logl, decreasing = T)[1:sols]
}
n <- 1
parmat <- matrix(NA, nrow = length(index), ncol = 3)
for(i in index){
parmat[n, ] <- lhs[[i]]$par
n <- n + 1
}
# Muestreamos las mejores combinaciones de parámetros, cada uno de ellos
# independientemente. De esta forma estamos rompiendo las posibles
# correlaciones entre los parámetros, y en algún sentido, hacemos la
# aproximación menos bayesiana al no samplear la distribución multidimensional
# de los parámetros.
seeds <- t(apply(X = parmat, MARGIN = 2, sample, size = 100000, replace = T))
rm(parmat)
rm(lhs)
print(paste0("Round: ", round, ";  Best likelihood: ", best2,
"; Solutions: ", sols, "\n"))
best <- best2
round <- round + 1
}
output <- load("~/MAD_MODEL/SUR_MODEL/Code/param_MAD_MODEL1.RData")
out_mat <- matrix(0, nrow = 10, ncol = 3)
out_mat <- matrix(0, nrow = 10, ncol = 4x)
out_mat <- matrix(0, nrow = 10, ncol = 4)
for(i in c(1:10)){
out_mat[i,1] = lhs[[i]]$value
out_mat[i,2:4] = lhs[[i]]$par
}
mat_sort <- out_mat[order(out_mat[,1], decreasing = F),]
View(mat_sort)
View(mat_sort)
output <- load("~/MAD_MODEL/VECTOR_MODEL/OUTPUT/param_VECTOR_MODEL1.RData")
out_mat <- matrix(0, nrow = 10, ncol = 4)
out_mat <- matrix(0, nrow = 10, ncol = 2)
for(i in c(1:10)){
out_mat[i,1] = lhs[[i]]$value
out_mat[i,2] = lhs[[i]]$par
}
mat_sort <- out_mat[order(out_mat[,1], decreasing = F),]
View(mat_sort)
View(mat_sort)
# Easy plots:
output <- load("~/Documents/PHD/2021/SUR_Model/PARAM_ESTIMATION/MH/Output/chain_MH_op1e+05.RData")
rm(list = ls())
library("parallel")
library("tidyverse")
library("deSolve")
library("coda")
# True param:
true1 = 0.1
trueSD = 1
# Easy plots:
output <- load("~/Documents/PHD/2021/SUR_Model/PARAM_ESTIMATION/MH/Output/chain_MH_op1e+05.RData")
burnIn = 500
acceptance = 1-mean(duplicated(chain[-(1:burnIn),]))
par(mfrow = c(2,4))
hist(chain[-(1:burnIn),1],nclass=30, main="Posterior of a", xlab="True value = red line" )
abline(v = mean(chain[-(1:burnIn),1]))
abline(v = true1, col="red" )
hist(chain[-(1:burnIn),2],nclass=30, main="Posterior of sd", xlab="True value = red line")
abline(v = mean(chain[-(1:burnIn),2]) )
abline(v = trueSD, col="red" )
plot(chain[-(1:burnIn),1], type = "l", xlab="True value = red line" , main = "Chain values of a", )
abline(h = true1, col="red" )
plot(chain[-(1:burnIn),2], type = "l", xlab="True value = red line" , main = "Chain values of sd", )
abline(h = trueSD, col="red" )
# Plots from coda package:
output <- load("~/Documents/PHD/2021/Mosquito_model/OUTPUT/chain_MH_op10000.RData")
burnIn = 5000
acceptance = 1-mean(duplicated(chain[-(1:burnIn),]))
par(mfrow = c(2,4))
hist(chain[-(1:burnIn),1],nclass=30, main="Posterior of a", xlab="True value = red line" )
abline(v = mean(chain[-(1:burnIn),1]))
abline(v = true1, col="red" )
hist(chain[-(1:burnIn),2],nclass=30, main="Posterior of sd", xlab="True value = red line")
abline(v = mean(chain[-(1:burnIn),2]) )
abline(v = trueSD, col="red" )
plot(chain[-(1:burnIn),1], type = "l", xlab="True value = red line" , main = "Chain values of a", )
burnIn = 1
acceptance = 1-mean(duplicated(chain[-(1:burnIn),]))
par(mfrow = c(2,4))
hist(chain[-(1:burnIn),1],nclass=30, main="Posterior of a", xlab="True value = red line" )
abline(v = mean(chain[-(1:burnIn),1]))
abline(v = true1, col="red" )
hist(chain[-(1:burnIn),2],nclass=30, main="Posterior of sd", xlab="True value = red line")
abline(v = mean(chain[-(1:burnIn),2]) )
abline(v = trueSD, col="red" )
plot(chain[-(1:burnIn),1], type = "l", xlab="True value = red line" , main = "Chain values of a", )
abline(h = true1, col="red" )
plot(chain[-(1:burnIn),2], type = "l", xlab="True value = red line" , main = "Chain values of sd", )
abline(h = trueSD, col="red" )
